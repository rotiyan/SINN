#!/usr/bin/env python
# -*- coding: utf-8 -*-
from abc import ABCMeta, abstractmethod
import numpy as np
import torch
import torch.nn.functional as F
from torch.nn.modules.loss import _Loss


class StatLoss(_Loss, metaclass=ABCMeta):
    '''Base class for all statistic-based loss functions. This is an abstract
    class because it only handles the processing for the 'target' properties,
    and leaves the definition of actual comparison operations to concrete
    subclasses.
    '''

    @classmethod
    def from_expr(cls, expr, t, **options):
        '''Specify the target statistic function with an expression
        at given evaluation points.

        Parameters
        ----------
        expr: callable
            A function to be evaluated at the given points.
        t: list-like
            A list of uniformly spaced grid points on which the expression will
            be evaluated.
        options: keyword argument list
            To be forwarded to `__init__`.
        '''
        return cls(np.fromiter(map(expr, t), dtype=np.float32), **options)

    def __init__(self, target, pointwise_loss='mse_loss', device='cpu',
                 **kwargs):
        '''Direct specification of the target statistic function in discretized
        form.

        Parameters
        ----------
        array: list-like The target statistic function.
        '''
        super().__init__()
        self._target = torch.tensor(target, dtype=torch.float32, device=device)
        if callable(pointwise_loss):
            self._loss = pointwise_loss
        else:
            try:
                self._loss = getattr(F, pointwise_loss)
            except AttributeError as e:
                raise RuntimeError(f'Unrecognized pointwise loss. Error:\n{e}')
        self.__dict__.update(**kwargs)

    @staticmethod
    def acf(x, lags=None, method='fft'):
        x = x - x.mean()
        T = x.shape[0]
        if method == 'fft':
            f = torch.fft.fft(x, x.shape[0] * 2 - 1, dim=0)
            acf = torch.fft.ifft(
                f * f.conj(), dim=0
            ).real[
                :x.shape[0]
            ].mean(axis=1)
            return acf[:lags, ...] / acf[0, ...]
        elif method == 'bruteforce':
            x_squeeze = x.squeeze(-1)  
        
            # Compute cross-correlation matrix M.
            # M[i, j] = sum_{c} x_squeeze[i, c] * x_squeeze[j, c]
            M = torch.matmul(x_squeeze, x_squeeze.T)  
        
            # For each lag k, get the numerator as the sum of the k-th diagonal of M.
            num = torch.stack([torch.diagonal(M, offset=k).sum() for k in range(T)])  # shape: (T,)
        
            # 5Compute denominator: first sum squares of x over channels for each time.
            s = (x_squeeze ** 2).sum(dim=1)  # shape: (T,)
            # Prepend zero to compute cumulative sums easily.
            cumsum_s = torch.cat([torch.zeros(1, device=x.device), torch.cumsum(s, dim=0)])
            # For each lag k, define:
            #  S1(k) = sum_{t=0}^{T-k-1} s[t] = cumsum_s[T-k]
            #  S2(k) = sum_{t=k}^{T-1} s[t] = cumsum_s[T] - cumsum_s[k]
            denom = torch.sqrt(torch.stack(
                [cumsum_s[T - k] * (cumsum_s[T] - cumsum_s[k]) for k in range(T)]
            ))
        
            # For safety, add a very small epsilon to the denominator.
            eps = 1e-8
            acf_all = num / (denom + eps)  # shape: (T,)
        
            # 6. Determine the desired lags.
            if lags is None:
                 desired_lags = torch.arange(T, device=x.device)
            elif isinstance(lags, int):
                 desired_lags = torch.arange(lags, device=x.device)
            else:
                desired_lags = torch.tensor(lags, dtype=torch.long, device=x.device)
        
            # Return results in a shape that preserves the extra dimension
            # so that the output shape is (len(desired_lags), 1)
            return acf_all[desired_lags].unsqueeze(-1)
        else:
            raise NotImplementedError(f'Unknown method {method}.')

    @staticmethod
    def gauss_kde(x, lower, upper, n, bw=None):
        x = torch.ravel(x)
        grid = torch.linspace(lower, upper, n, device=x.device)
        if bw is None:
            bw = len(x)**(-1 / 5)
        norm_factor = (2 * np.pi)**0.5 * len(x) * bw
        return torch.sum(
            torch.exp(
                -0.5 * torch.square(
                    (x[:, None] - grid[None, :]) / bw
                )
            ),
            axis=0
        ) / norm_factor

    @abstractmethod
    def forward(self, input):
        '''Evaluate the input stochastic processes against the target statistic
        function.

        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The input trajectory as generated by an NN.
        '''


class ACFLoss(StatLoss):

    @classmethod
    def from_empirical_data(cls, data, lags, **options):
        '''Create target ACF from a number of empirically observed trajectories.

        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The empirically observed trajectories.
        options: keyword argument list
            To be forwarded to `__init__`.
        '''
        return cls(cls.acf(data, lags=lags), **options)

    def forward(self, input):
        '''
        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The input trajectory as generated by an NN.
        '''
        _input = self.acf(input, lags=len(self._target))
        return self._loss(_input, self._target)


class BruteForceACFLoss(StatLoss):

    @classmethod
    def from_empirical_data(cls, data, lags, **options):
        '''Create target ACF from a number of empirically observed trajectories.

        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The empirically observed trajectories.
        options: keyword argument list
            To be forwarded to `__init__`.
        '''
        return cls(cls.acf(data, lags=lags, method='bruteforce'), **options)

    def forward(self, input):
        '''
        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The input trajectory as generated by an NN.
        '''
        _input = self.acf(input, lags=len(self._target), method='bruteforce')
        return self._loss(_input, self._target)


class RandomBruteForceACFLoss(StatLoss):

    @classmethod
    def from_empirical_data(cls, data, lags, **options):
        '''Create target ACF from a number of empirically observed trajectories.

        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The empirically observed trajectories.
        options: keyword argument list
            To be forwarded to `__init__`.
        '''
        return cls(cls.acf(data, lags=lags, method='bruteforce'), **options)

    def forward(self, input):
        '''
        Parameters
        ----------
        input: tensor of shape (trajectory_length, n_batch, n_variables)
            The input trajectory as generated by an NN.
        '''
        lags = np.random.choice(len(self._target), self.sample_lags, False)
        _input = self.acf(input, lags=lags, method='bruteforce')
        return self._loss(_input, self._target[lags])


class DensityLoss(StatLoss):

    @classmethod
    def from_empirical_data(cls, data, lower, upper, n, **options):
        '''Create target PDF from a number of empirically observed trajectories.

        Parameters
        ----------
        input: tensor of any shape
            The empirically observed trajectories.
        options: keyword argument list
            To be forwarded to `__init__`.
        '''
        return cls(
            cls.gauss_kde(data, lower=lower, upper=upper, n=n),
            **options, lower=lower, upper=upper, n=n
        )

    def forward(self, input):
        '''
        Parameters
        ----------
        input: tensor of any shape
            The input trajectory as generated by an NN.
        '''
        _input = self.gauss_kde(
            input, lower=self.lower, upper=self.upper, n=self.n
        )
        return self._loss(_input, self._target)


def make_loss(stat, data, loss_type=['mse_loss', 'l1_loss'], **kwargs):
    '''
    Create a loss function.

    Parameters
    ----------
    stat: 'pdf' or 'acf[fft]' or 'acf[bruteforce]' or 'acf[randombrute]'
        Statistics to compute
    data: tensor
        Target statistics function or sample trajectories.
    loss_type: list
        Lower-levle loss functions to use.
    kwargs:
        additional arguments to pass to the loss function

    Returns
    -------
    loss: callable
        A loss function
    '''
    if stat == 'pdf':
        loss_cls = DensityLoss
    elif stat == 'acf[fft]':
        loss_cls = ACFLoss
    elif stat == 'acf[bruteforce]':
        loss_cls = BruteForceACFLoss
    elif stat == 'acf[randombrute]':
        loss_cls = RandomBruteForceACFLoss
    else:
        raise RuntimeError(f'Unknown stat {stat}.')

    def lower_level_loss(a, b):
        return torch.sum([getattr(F, ls)(a, b) for ls in loss_type])

    if len(data.shape) == 1:
        return loss_cls(
            data,
            loss=lower_level_loss,
            **kwargs
        )
    elif len(data.shape) == 3:
        return loss_cls.from_empirical_data(
            data,
            loss=lower_level_loss,
            **kwargs
        )
    else:
        raise RuntimeError('Unknown truth data format.')
